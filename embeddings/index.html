
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="../images/logo.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-7.1.1">
    
    
      
        <title>Embeddings - txtai</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.9299cb39.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ef6f36e2.min.css">
        
          
          
          <meta name="theme-color" content="#2094f3">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="blue" data-md-color-accent="blue">
  
    
    <script>function __prefix(e){return new URL("..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#embeddings" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="txtai" class="md-header__button md-logo" aria-label="txtai" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            txtai
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Embeddings
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/neuml/txtai/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    neuml/txtai
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="txtai" class="md-nav__button md-logo" aria-label="txtai" data-md-component="logo">
      
  <img src="../images/logo.png" alt="logo">

    </a>
    txtai
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/neuml/txtai/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    neuml/txtai
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../install/" class="md-nav__link">
        Installation
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../examples/" class="md-nav__link">
        Examples
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Embeddings
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Embeddings
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    Configuration
  </a>
  
    <nav class="md-nav" aria-label="Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#method" class="md-nav__link">
    method
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#path" class="md-nav__link">
    path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tokenize" class="md-nav__link">
    tokenize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#storevectors" class="md-nav__link">
    storevectors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scoring" class="md-nav__link">
    scoring
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pca" class="md-nav__link">
    pca
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backend" class="md-nav__link">
    backend
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#annoy" class="md-nav__link">
    annoy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#faiss" class="md-nav__link">
    faiss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hnsw" class="md-nav__link">
    hnsw
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantize" class="md-nav__link">
    quantize
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.batchsearch" class="md-nav__link">
    batchsearch()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.batchsimilarity" class="md-nav__link">
    batchsimilarity()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.batchtransform" class="md-nav__link">
    batchtransform()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.index" class="md-nav__link">
    index()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.load" class="md-nav__link">
    load()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.save" class="md-nav__link">
    save()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.score" class="md-nav__link">
    score()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.search" class="md-nav__link">
    search()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.similarity" class="md-nav__link">
    similarity()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.transform" class="md-nav__link">
    transform()
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        Pipelines
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Pipelines" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Pipelines
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pipelines/overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pipelines/extractor/" class="md-nav__link">
        Extractor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pipelines/labels/" class="md-nav__link">
        Labels
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pipelines/similarity/" class="md-nav__link">
        Similarity
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pipelines/summary/" class="md-nav__link">
        Summary
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pipelines/textractor/" class="md-nav__link">
        Textractor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pipelines/transcription/" class="md-nav__link">
        Transcription
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pipelines/translation/" class="md-nav__link">
        Translation
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../workflows/" class="md-nav__link">
        Workflows
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        API
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    Configuration
  </a>
  
    <nav class="md-nav" aria-label="Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#method" class="md-nav__link">
    method
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#path" class="md-nav__link">
    path
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tokenize" class="md-nav__link">
    tokenize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#storevectors" class="md-nav__link">
    storevectors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scoring" class="md-nav__link">
    scoring
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pca" class="md-nav__link">
    pca
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backend" class="md-nav__link">
    backend
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#annoy" class="md-nav__link">
    annoy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#faiss" class="md-nav__link">
    faiss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hnsw" class="md-nav__link">
    hnsw
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantize" class="md-nav__link">
    quantize
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.batchsearch" class="md-nav__link">
    batchsearch()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.batchsimilarity" class="md-nav__link">
    batchsimilarity()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.batchtransform" class="md-nav__link">
    batchtransform()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.index" class="md-nav__link">
    index()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.load" class="md-nav__link">
    load()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.save" class="md-nav__link">
    save()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.score" class="md-nav__link">
    score()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.search" class="md-nav__link">
    search()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.similarity" class="md-nav__link">
    similarity()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai.embeddings.base.Embeddings.transform" class="md-nav__link">
    transform()
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/neuml/txtai/edit/master/docs/embeddings.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="embeddings">Embeddings</h1>
<p>An Embeddings instance is the engine that provides similarity search. Embeddings can be used to run ad-hoc similarity comparisions or build/search large indices.</p>
<p>Embeddings parameters are set through the constructor. Examples below.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Transformers embeddings model</span>
<span class="n">Embeddings</span><span class="p">({</span><span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span>
            <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers/bert-base-nli-mean-tokens&quot;</span><span class="p">})</span>

<span class="c1"># Word embeddings model</span>
<span class="n">Embeddings</span><span class="p">({</span><span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="n">vectors</span><span class="p">,</span>
            <span class="s2">&quot;storevectors&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;scoring&quot;</span><span class="p">:</span> <span class="s2">&quot;bm25&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pca&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s2">&quot;quantize&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
</code></pre></div>
<h2 id="configuration">Configuration</h2>
<h3 id="method">method</h3>
<div class="highlight"><pre><span></span><code><span class="nt">method</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">transformers|words</span>
</code></pre></div>
<p>Sets the sentence embeddings method to use. When set to <em>transformers</em>, the embeddings object builds sentence embeddings using the sentence transformers. Otherwise a word embeddings model is used. Defaults to words.</p>
<h3 id="path">path</h3>
<div class="highlight"><pre><span></span><code><span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">string</span>
</code></pre></div>
<p>Required field that sets the path for a vectors model. When method set to <em>transformers</em>, this must be a path to a Hugging Face transformers model. Otherwise,
it must be a path to a local word embeddings model.</p>
<h3 id="tokenize">tokenize</h3>
<div class="highlight"><pre><span></span><code><span class="nt">tokenize</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">boolean</span>
</code></pre></div>
<p>Enables string tokenization (defaults to true). This method applies tokenization rules that work best with English language text and help increase the
quality of English language sentence embeddings. This should be disabled when working with non-English text.</p>
<h3 id="storevectors">storevectors</h3>
<div class="highlight"><pre><span></span><code><span class="nt">storevectors</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">boolean</span>
</code></pre></div>
<p>Enables copying of a vectors model set in path into the embeddings models output directory on save. This option enables a fully encapsulated index with no external file dependencies.</p>
<h3 id="scoring">scoring</h3>
<div class="highlight"><pre><span></span><code><span class="nt">scoring</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">bm25|tfidf|sif</span>
</code></pre></div>
<p>For word embedding models, a scoring model allows building weighted averages of word vectors for a given sentence. Supports BM25, tf-idf and SIF (smooth inverse frequency) methods. If a scoring method is not provided, mean sentence embeddings are built.</p>
<h3 id="pca">pca</h3>
<div class="highlight"><pre><span></span><code><span class="nt">pca</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">int</span>
</code></pre></div>
<p>Removes <em>n</em> principal components from generated sentence embeddings. When enabled, a TruncatedSVD model is built to help with dimensionality reduction. After pooling of vectors creates a single sentence embedding, this method is applied.</p>
<h3 id="backend">backend</h3>
<div class="highlight"><pre><span></span><code><span class="nt">backend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">annoy|faiss|hnsw</span>
</code></pre></div>
<p>Approximate Nearest Neighbor (ANN) index backend for storing generated sentence embeddings. Defaults to Faiss for Linux/macOS and Annoy for Windows. Faiss currently is not supported on Windows.</p>
<p>Backend-specific settings are set with a corresponding configuration object having the same name as the backend (i.e. annoy, faiss, or hnsw). None of these are required and are set to defaults if omitted.</p>
<h3 id="annoy">annoy</h3>
<div class="highlight"><pre><span></span><code><span class="nt">annoy</span><span class="p">:</span>
    <span class="nt">ntrees</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">number of trees (int) - defaults to 10</span>
    <span class="nt">searchk</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">search_k search setting (int) - defaults to -1</span>
</code></pre></div>
<p>See <a href="https://github.com/spotify/annoy#full-python-api">Annoy documentation</a> for more information on these parameters.</p>
<h3 id="faiss">faiss</h3>
<div class="highlight"><pre><span></span><code><span class="nt">faiss</span><span class="p">:</span>
    <span class="nt">components</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Comma separated list of components - defaults to None</span>
    <span class="nt">nprobe</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">search probe setting (int) - defaults to 6</span>
</code></pre></div>
<p>See Faiss documentation on the <a href="https://github.com/facebookresearch/faiss/wiki/The-index-factory">index factory</a> and <a href="https://github.com/facebookresearch/faiss/wiki/Faster-search">search</a> for more information on these parameters.</p>
<h3 id="hnsw">hnsw</h3>
<div class="highlight"><pre><span></span><code><span class="nt">hnsw</span><span class="p">:</span>
    <span class="nt">efconstruction</span><span class="p">:</span>  <span class="l l-Scalar l-Scalar-Plain">ef_construction param for init_index (int) - defaults to 200</span>
    <span class="nt">m</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">M param for init_index (int) - defaults to 16</span>
    <span class="nt">randomseed</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">random-seed param for init_index (init) - defaults to 100</span>
    <span class="nt">efsearch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ef search param (int) - defaults to None and not set</span>
</code></pre></div>
<p>See <a href="https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md">Hnswlib documentation</a> for more information on these parameters.</p>
<h3 id="quantize">quantize</h3>
<div class="highlight"><pre><span></span><code><span class="nt">quantize</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">boolean</span>
</code></pre></div>
<p>Enables quanitization of generated sentence embeddings. If the index backend supports it, sentence embeddings will be stored with 8-bit precision vs 32-bit.
Only Faiss currently supports quantization.</p>


  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.__init__">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h2>

    <div class="doc doc-contents first">

      <p>Creates a new Embeddings model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>config</code></td>
        <td><code></code></td>
        <td><p>embeddings configuration</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a new Embeddings model.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: embeddings configuration</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Configuration</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

    <span class="c1"># Embeddings model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Dimensionality reduction model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lsa</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Embedding scoring method - weighs each word in a sentence</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">ScoringFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;scoring&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scoring&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="c1"># Sentence vectors model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loadVectors</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="k">else</span> <span class="kc">None</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.batchsearch">
<code class="highlight language-python"><span class="n">batchsearch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Finds documents in the embeddings model most similar to the input queries. Returns
a list of (id, score) sorted by highest score per query, where id is the document id
in the embeddings model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>queries</code></td>
        <td><code></code></td>
        <td><p>queries text|tokens</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>limit</code></td>
        <td><code></code></td>
        <td><p>maximum results</p></td>
        <td><code>3</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code></code></td>
      <td><p>list of (id, score) per query</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">batchsearch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Finds documents in the embeddings model most similar to the input queries. Returns</span>
<span class="sd">    a list of (id, score) sorted by highest score per query, where id is the document id</span>
<span class="sd">    in the embeddings model.</span>

<span class="sd">    Args:</span>
<span class="sd">        queries: queries text|tokens</span>
<span class="sd">        limit: maximum results</span>

<span class="sd">    Returns:</span>
<span class="sd">        list of (id, score) per query</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Convert queries to embedding vectors</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span> <span class="k">for</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">queries</span><span class="p">])</span>

    <span class="c1"># Search embeddings index</span>
    <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">limit</span><span class="p">)</span>

    <span class="c1"># Map ids if id mapping available</span>
    <span class="n">lookup</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ids&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lookup</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[[(</span><span class="n">lookup</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">r</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">results</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.batchsimilarity">
<code class="highlight language-python"><span class="n">batchsimilarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">texts</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Computes the similarity between list of queries and list of text. Returns a list
of (id, score) sorted by highest score per query, where id is the index in texts.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>queries</code></td>
        <td><code></code></td>
        <td><p>queries text|tokens</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>texts</code></td>
        <td><code></code></td>
        <td><p>list of text|tokens</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code></code></td>
      <td><p>list of (id, score) per query</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">batchsimilarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">texts</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the similarity between list of queries and list of text. Returns a list</span>
<span class="sd">    of (id, score) sorted by highest score per query, where id is the index in texts.</span>

<span class="sd">    Args:</span>
<span class="sd">        queries: queries text|tokens</span>
<span class="sd">        texts: list of text|tokens</span>

<span class="sd">    Returns:</span>
<span class="sd">        list of (id, score) per query</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Convert queries to embedding vectors</span>
    <span class="n">queries</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span> <span class="k">for</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">queries</span><span class="p">])</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">])</span>

    <span class="c1"># Dot product on normalized vectors is equal to cosine similarity</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">texts</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="c1"># Add index id and sort desc based on score</span>
    <span class="k">return</span> <span class="p">[</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">score</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.batchtransform">
<code class="highlight language-python"><span class="n">batchtransform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Transforms documents into embeddings vectors. Document text will be tokenized if not pre-tokenized.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>documents</code></td>
        <td><code></code></td>
        <td><p>list of (id, text|tokens, tags)</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code></code></td>
      <td><p>embeddings vectors</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">batchtransform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transforms documents into embeddings vectors. Document text will be tokenized if not pre-tokenized.</span>

<span class="sd">    Args:</span>
<span class="sd">        documents: list of (id, text|tokens, tags)</span>

<span class="sd">    Returns:</span>
<span class="sd">        embeddings vectors</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">document</span><span class="p">)</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.index">
<code class="highlight language-python"><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Builds an embeddings index.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>documents</code></td>
        <td><code></code></td>
        <td><p>list of (id, text|tokens, tags)</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builds an embeddings index.</span>

<span class="sd">    Args:</span>
<span class="sd">        documents: list of (id, text|tokens, tags)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Transform documents to embeddings vectors</span>
    <span class="n">ids</span><span class="p">,</span> <span class="n">dimensions</span><span class="p">,</span> <span class="n">stream</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

    <span class="c1"># Load streamed embeddings back to memory</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">),</span> <span class="n">dimensions</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">queue</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">embeddings</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">queue</span><span class="p">)</span>

    <span class="c1"># Remove temporary file</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>

    <span class="c1"># Build LSA model (if enabled). Remove principal components from embeddings.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pca&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lsa</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buildLSA</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;pca&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">removePC</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

    <span class="c1"># Normalize embeddings</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

    <span class="c1"># Save embeddings metadata</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ids</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;dimensions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dimensions</span>

    <span class="c1"># Create embeddings index</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">ANNFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

    <span class="c1"># Build the index</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.load">
<code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Loads a pre-trained model.</p>
<p>Models have the following files:
    config - configuration
    embeddings - sentence embeddings index
    lsa - LSA model, used to remove the principal component(s)
    scoring - scoring model used to weigh word vectors
    vectors - vectors model</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>path</code></td>
        <td><code></code></td>
        <td><p>input directory path</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads a pre-trained model.</span>

<span class="sd">    Models have the following files:</span>
<span class="sd">        config - configuration</span>
<span class="sd">        embeddings - sentence embeddings index</span>
<span class="sd">        lsa - LSA model, used to remove the principal component(s)</span>
<span class="sd">        scoring - scoring model used to weigh word vectors</span>
<span class="sd">        vectors - vectors model</span>

<span class="sd">    Args:</span>
<span class="sd">        path: input directory path</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Index configuration</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/config&quot;</span> <span class="o">%</span> <span class="n">path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

        <span class="c1"># Build full path to embedding vectors file</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;storevectors&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">])</span>

    <span class="c1"># Sentence embeddings index</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">ANNFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/embeddings&quot;</span> <span class="o">%</span> <span class="n">path</span><span class="p">)</span>

    <span class="c1"># Dimensionality reduction</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pca&quot;</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/lsa&quot;</span> <span class="o">%</span> <span class="n">path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lsa</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

    <span class="c1"># Embedding scoring</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scoring&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">ScoringFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;scoring&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

    <span class="c1"># Sentence vectors model - transforms text into sentence embeddings</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loadVectors</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.save">
<code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Saves a model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>path</code></td>
        <td><code></code></td>
        <td><p>output directory path</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Saves a model.</span>

<span class="sd">    Args:</span>
<span class="sd">        path: output directory path</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
        <span class="c1"># Create output directory, if necessary</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Copy vectors file</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;storevectors&quot;</span><span class="p">):</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">copyfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">],</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">])))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">])</span>

        <span class="c1"># Write index configuration</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/config&quot;</span> <span class="o">%</span> <span class="n">path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>

        <span class="c1"># Write sentence embeddings index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/embeddings&quot;</span> <span class="o">%</span> <span class="n">path</span><span class="p">)</span>

        <span class="c1"># Save dimensionality reduction</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lsa</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/lsa&quot;</span> <span class="o">%</span> <span class="n">path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lsa</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>

        <span class="c1"># Save embedding scoring</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.score">
<code class="highlight language-python"><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Builds a scoring index.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>documents</code></td>
        <td><code></code></td>
        <td><p>list of (id, text|tokens, tags)</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builds a scoring index.</span>

<span class="sd">    Args:</span>
<span class="sd">        documents: list of (id, text|tokens, tags)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">:</span>
        <span class="c1"># Build scoring index over documents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.search">
<code class="highlight language-python"><span class="n">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Finds documents in the embeddings model most similar to the input query. Returns
a list of (id, score) sorted by highest score, where id is the document id in
the embeddings model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>query</code></td>
        <td><code></code></td>
        <td><p>query text|tokens</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>limit</code></td>
        <td><code></code></td>
        <td><p>maximum results</p></td>
        <td><code>3</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code></code></td>
      <td><p>list of (id, score)</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Finds documents in the embeddings model most similar to the input query. Returns</span>
<span class="sd">    a list of (id, score) sorted by highest score, where id is the document id in</span>
<span class="sd">    the embeddings model.</span>

<span class="sd">    Args:</span>
<span class="sd">        query: query text|tokens</span>
<span class="sd">        limit: maximum results</span>

<span class="sd">    Returns:</span>
<span class="sd">        list of (id, score)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchsearch</span><span class="p">([</span><span class="n">query</span><span class="p">],</span> <span class="n">limit</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.similarity">
<code class="highlight language-python"><span class="n">similarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">texts</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Computes the similarity between query and list of text. Returns a list of
(id, score) sorted by highest score, where id is the index in texts.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>query</code></td>
        <td><code></code></td>
        <td><p>query text|tokens</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>texts</code></td>
        <td><code></code></td>
        <td><p>list of text|tokens</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code></code></td>
      <td><p>list of (id, score)</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">similarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">texts</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the similarity between query and list of text. Returns a list of</span>
<span class="sd">    (id, score) sorted by highest score, where id is the index in texts.</span>

<span class="sd">    Args:</span>
<span class="sd">        query: query text|tokens</span>
<span class="sd">        texts: list of text|tokens</span>

<span class="sd">    Returns:</span>
<span class="sd">        list of (id, score)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchsimilarity</span><span class="p">([</span><span class="n">query</span><span class="p">],</span> <span class="n">texts</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 class="doc doc-heading" id="txtai.embeddings.base.Embeddings.transform">
<code class="highlight language-python"><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">document</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Transforms document into an embeddings vector. Document text will be tokenized if not pre-tokenized.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>document</code></td>
        <td><code></code></td>
        <td><p>(id, text|tokens, tags)</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code></code></td>
      <td><p>embeddings vector</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>txtai/embeddings/base.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">document</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transforms document into an embeddings vector. Document text will be tokenized if not pre-tokenized.</span>

<span class="sd">    Args:</span>
<span class="sd">        document: (id, text|tokens, tags)</span>

<span class="sd">    Returns:</span>
<span class="sd">        embeddings vector</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Convert document into sentence embedding</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>

    <span class="c1"># Reduce the dimensionality of the embeddings. Scale the embeddings using this</span>
    <span class="c1"># model to reduce the noise of common but less relevant terms.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lsa</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">removePC</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

    <span class="c1"># Normalize embeddings</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">embedding</span>
</code></pre></div>
        </details>
    </div>

  </div>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        <a href="../examples/" class="md-footer__link md-footer__link--prev" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Examples
            </div>
          </div>
        </a>
      
      
        <a href="../pipelines/overview/" class="md-footer__link md-footer__link--next" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Overview
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
             NeuML LLC, Apache-2.0 License
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../assets/javascripts/workers/search.fe42c31b.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.7353b375.min.js"></script>
      
    
  </body>
</html>